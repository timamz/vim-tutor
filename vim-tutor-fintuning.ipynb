{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T15:30:28.490797Z",
     "iopub.status.busy": "2025-05-27T15:30:28.490415Z",
     "iopub.status.idle": "2025-05-27T15:31:00.097231Z",
     "shell.execute_reply": "2025-05-27T15:31:00.096061Z",
     "shell.execute_reply.started": "2025-05-27T15:30:28.490773Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -qqq bitsandbytes\n",
    "!pip install -qqq torch\n",
    "!pip install -qqq transformers\n",
    "!pip install -qqq peft\n",
    "!pip install -qqq accelerate\n",
    "!pip install -qqq datasets\n",
    "!pip install -qqq einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T15:31:00.098671Z",
     "iopub.status.busy": "2025-05-27T15:31:00.098369Z",
     "iopub.status.idle": "2025-05-27T15:31:38.309478Z",
     "shell.execute_reply": "2025-05-27T15:31:38.308683Z",
     "shell.execute_reply.started": "2025-05-27T15:31:00.098646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    EarlyStoppingCallback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T15:31:38.310991Z",
     "iopub.status.busy": "2025-05-27T15:31:38.310419Z",
     "iopub.status.idle": "2025-05-27T15:31:38.315385Z",
     "shell.execute_reply": "2025-05-27T15:31:38.314612Z",
     "shell.execute_reply.started": "2025-05-27T15:31:38.310955Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\".*torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly.*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T15:31:38.318716Z",
     "iopub.status.busy": "2025-05-27T15:31:38.318331Z",
     "iopub.status.idle": "2025-05-27T15:31:38.368218Z",
     "shell.execute_reply": "2025-05-27T15:31:38.367354Z",
     "shell.execute_reply.started": "2025-05-27T15:31:38.318679Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data and training scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T15:31:38.369777Z",
     "iopub.status.busy": "2025-05-27T15:31:38.369560Z",
     "iopub.status.idle": "2025-05-27T15:31:38.375438Z",
     "shell.execute_reply": "2025-05-27T15:31:38.374754Z",
     "shell.execute_reply.started": "2025-05-27T15:31:38.369758Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "DATA_PATH = \"/kaggle/input/vim-data/final.csv\"\n",
    "\n",
    "# 4-bit quantization config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T15:31:38.376534Z",
     "iopub.status.busy": "2025-05-27T15:31:38.376296Z",
     "iopub.status.idle": "2025-05-27T15:31:39.897609Z",
     "shell.execute_reply": "2025-05-27T15:31:39.896928Z",
     "shell.execute_reply.started": "2025-05-27T15:31:38.376515Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c40d0b485d5453399300ca34c5c302f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74662b8b74604179b10af58f055938ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26019465844f4bbe973a13733a8774bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21115c2add6b4befb1023d0e16a493ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T15:31:39.898537Z",
     "iopub.status.busy": "2025-05-27T15:31:39.898327Z",
     "iopub.status.idle": "2025-05-27T15:31:39.951265Z",
     "shell.execute_reply": "2025-05-27T15:31:39.950597Z",
     "shell.execute_reply.started": "2025-05-27T15:31:39.898519Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2368\n",
      "Validation size: 264\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH).dropna(subset=[\"description\", \"key\"])\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=SEED)\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Validation size:\", len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T15:31:39.952241Z",
     "iopub.status.busy": "2025-05-27T15:31:39.951957Z",
     "iopub.status.idle": "2025-05-27T15:31:41.201144Z",
     "shell.execute_reply": "2025-05-27T15:31:41.200401Z",
     "shell.execute_reply.started": "2025-05-27T15:31:39.952218Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a030aa80fa425baee1563e4c0c0e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84adcb9015f64b74bbc17fbd8d2d7a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/264 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_prompt(example):\n",
    "    prompt = f\"How to {example['description']} using vim motions? \" \\\n",
    "             f\"Write only the symbol sequence representing the vim motion.\"\n",
    "    return prompt, example[\"key\"]\n",
    "\n",
    "def tokenize_example(example):\n",
    "    prompt_text, answer_text = generate_prompt(example)\n",
    "    full_text = prompt_text + \"\\n\" + answer_text\n",
    "    tokenized = tokenizer(\n",
    "        full_text,\n",
    "        max_length=64,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    return tokenized\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df).map(tokenize_example)\n",
    "val_dataset = Dataset.from_pandas(val_df).map(tokenize_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T15:31:41.202282Z",
     "iopub.status.busy": "2025-05-27T15:31:41.202006Z",
     "iopub.status.idle": "2025-05-27T15:31:41.212338Z",
     "shell.execute_reply": "2025-05-27T15:31:41.211284Z",
     "shell.execute_reply.started": "2025-05-27T15:31:41.202247Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_with_lora(\n",
    "    rank_value: int = 8,\n",
    "    lora_dropout: float = 0.05,\n",
    "    learning_rate: float = 1e-4,\n",
    "    weight_decay: float = 0,\n",
    "    epochs: int = 10,\n",
    "    output_dir_prefix: str = \"finetune_qwen_vim\",\n",
    "    verbose=True,\n",
    "    save_model=True,\n",
    "    scheduler='cosine_with_restarts',\n",
    "    scheduler_kwargs={},\n",
    "    early_stopping_patience=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains Qwen model with LoRA for the specified rank, dropout, \n",
    "    learning rate, and weight decay.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"\\n=== Training with LoRA rank={rank_value}, dropout={lora_dropout}, lr={learning_rate}, wd={weight_decay} ===\")\n",
    "    \n",
    "    # Load base model fresh\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        quantization_config=bnb_config\n",
    "    )\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "    # Create LoRA config\n",
    "    lora_config = LoraConfig(\n",
    "        r=rank_value,\n",
    "        lora_alpha=32,\n",
    "        # target_modules=[\"q_proj\", \"v_proj\"],          omit the line to train all parameters\n",
    "        lora_dropout=lora_dropout,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\"\n",
    "    )\n",
    "    \n",
    "    # Wrap model with PEFT\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    model.config.use_cache = False\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        eval_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        save_total_limit=1,\n",
    "        output_dir=f\"{output_dir_prefix}_rank_{rank_value}_dropout_{lora_dropout}_lr_{learning_rate}_wd_{weight_decay}\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='eval_loss',\n",
    "        greater_is_better=False,\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        fp16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        lr_scheduler_type=scheduler,\n",
    "        lr_scheduler_kwargs={'num_cycles': 10} if scheduler=='cosine_with_restarts' else scheduler_kwargs,\n",
    "        report_to=\"none\",\n",
    "        seed=SEED,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        disable_tqdm=False if verbose else True,\n",
    "        logging_strategy=\"epoch\" if verbose else \"no\"\n",
    "    )\n",
    "    \n",
    "    if early_stopping_patience:\n",
    "        early_stop_callback = EarlyStoppingCallback(\n",
    "            early_stopping_patience=early_stopping_patience,\n",
    "            early_stopping_threshold=0.0\n",
    "        )\n",
    "\n",
    "    # Create Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "        callbacks=[early_stop_callback]\n",
    "    )\n",
    "\n",
    "    # Training\n",
    "    trainer.train()\n",
    "\n",
    "    # Save LoRA adapter\n",
    "    if save_model:\n",
    "        lora_dir = f\"/kaggle/working/trained_{MODEL_NAME}\"\n",
    "        trainer.save_model(lora_dir)\n",
    "        if verbose:\n",
    "            print(f\"Best model saved to '{lora_dir}'.\")\n",
    "\n",
    "    # Evaluate on validation dataset to get final loss\n",
    "    eval_metrics = trainer.evaluate()\n",
    "    final_val_loss = eval_metrics[\"eval_loss\"]\n",
    "    \n",
    "    return final_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 0.5B model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T15:31:41.214009Z",
     "iopub.status.busy": "2025-05-27T15:31:41.213614Z",
     "iopub.status.idle": "2025-05-27T16:02:27.897683Z",
     "shell.execute_reply": "2025-05-27T16:02:27.896882Z",
     "shell.execute_reply.started": "2025-05-27T15:31:41.213969Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training with LoRA rank=32, dropout=0.05, lr=0.0001, wd=0.001 ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0e5224748742b697cd324bed711085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c46a8f0cdd4fe3af92d455bf2ee14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d007e62ea0364c9c9e6b24de534a02d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5032' max='8880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5032/8880 30:32 < 23:21, 2.75 it/s, Epoch 17/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.856900</td>\n",
       "      <td>1.302172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.145600</td>\n",
       "      <td>1.126271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.001000</td>\n",
       "      <td>1.045073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.914500</td>\n",
       "      <td>0.980919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.850300</td>\n",
       "      <td>0.943711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.797800</td>\n",
       "      <td>0.919739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.755200</td>\n",
       "      <td>0.896619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.716300</td>\n",
       "      <td>0.881569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.684600</td>\n",
       "      <td>0.872577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.867802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.627300</td>\n",
       "      <td>0.871436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.603600</td>\n",
       "      <td>0.856217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.581500</td>\n",
       "      <td>0.875707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.563300</td>\n",
       "      <td>0.873076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.542400</td>\n",
       "      <td>0.875064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.526500</td>\n",
       "      <td>0.878079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.512300</td>\n",
       "      <td>0.892386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved to '/kaggle/working/trained_Qwen/Qwen2.5-0.5B-Instruct'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8562170267105103"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "train_with_lora(\n",
    "    rank_value=32,\n",
    "    lora_dropout=0.05,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.001,\n",
    "    epochs=30,\n",
    "    scheduler='cosine',\n",
    "    early_stopping_patience=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 7B model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T16:02:27.898791Z",
     "iopub.status.busy": "2025-05-27T16:02:27.898549Z",
     "iopub.status.idle": "2025-05-27T17:51:07.502126Z",
     "shell.execute_reply": "2025-05-27T17:51:07.501316Z",
     "shell.execute_reply.started": "2025-05-27T16:02:27.898770Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training with LoRA rank=32, dropout=0.05, lr=0.0001, wd=0.001 ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99e9aee0af3454982f0e3869d78c3e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6cd3cbb99941edb75a0fddd731a6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/27.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcce391b65a841fca06956561f1e1674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c456c94727df4991baf5a45c7d5e8ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ab15a6247446a0a6674cf9c89a5c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd4d68a99b34173adb72de4eb5e9391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be16d7ba59746548679d93f9d8fe128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9302711522214ee3a9e1cbe56cdcb77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823b2c0019eb4ca39c555e1d4ebad00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2368' max='8880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2368/8880 1:45:45 < 4:51:05, 0.37 it/s, Epoch 8/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.317900</td>\n",
       "      <td>0.942748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.818900</td>\n",
       "      <td>0.839399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.722800</td>\n",
       "      <td>0.787783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.662100</td>\n",
       "      <td>0.768428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.615300</td>\n",
       "      <td>0.766744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.576300</td>\n",
       "      <td>0.769010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.541600</td>\n",
       "      <td>0.782582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.511100</td>\n",
       "      <td>0.789177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved to '/kaggle/working/trained_Qwen/Qwen2.5-7B-Instruct'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7667436003684998"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "train_with_lora(\n",
    "    rank_value=32,\n",
    "    lora_dropout=0.05,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.001,\n",
    "    epochs=30,\n",
    "    scheduler='cosine',\n",
    "    early_stopping_patience=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T17:51:07.503193Z",
     "iopub.status.busy": "2025-05-27T17:51:07.502921Z",
     "iopub.status.idle": "2025-05-27T17:51:13.901511Z",
     "shell.execute_reply": "2025-05-27T17:51:13.900292Z",
     "shell.execute_reply.started": "2025-05-27T17:51:07.503162Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/ (stored 0%)\n",
      "  adding: kaggle/working/trained_Qwen/ (stored 0%)\n",
      "  adding: kaggle/working/trained_Qwen/Qwen2.5-0.5B-Instruct/ (stored 0%)\n",
      "  adding: kaggle/working/trained_Qwen/Qwen2.5-0.5B-Instruct/README.md (deflated 66%)\n",
      "  adding: kaggle/working/trained_Qwen/Qwen2.5-0.5B-Instruct/adapter_model.safetensors (deflated 7%)\n",
      "  adding: kaggle/working/trained_Qwen/Qwen2.5-0.5B-Instruct/adapter_config.json (deflated 53%)\n",
      "  adding: kaggle/working/trained_Qwen/Qwen2.5-0.5B-Instruct/training_args.bin (deflated 51%)\n",
      "  adding: kaggle/working/trained_Qwen/Qwen2.5-7B-Instruct/ (stored 0%)\n",
      "  adding: kaggle/working/trained_Qwen/Qwen2.5-7B-Instruct/README.md (deflated 66%)\n",
      "  adding: kaggle/working/trained_Qwen/Qwen2.5-7B-Instruct/adapter_model.safetensors (deflated 8%)\n",
      "  adding: kaggle/working/trained_Qwen/Qwen2.5-7B-Instruct/adapter_config.json (deflated 53%)\n",
      "  adding: kaggle/working/trained_Qwen/Qwen2.5-7B-Instruct/training_args.bin (deflated 51%)\n",
      "  adding: kaggle/working/.virtual_documents/ (stored 0%)\n",
      "  adding: kaggle/working/finetune_qwen_vim_rank_32_dropout_0.05_lr_0.0001_wd_0.001/ (stored 0%)\n",
      "  adding: kaggle/working/finetune_qwen_vim_rank_32_dropout_0.05_lr_0.0001_wd_0.001/checkpoint-1480/ (stored 0%)\n",
      "  adding: kaggle/working/finetune_qwen_vim_rank_32_dropout_0.05_lr_0.0001_wd_0.001/checkpoint-1480/README.md (deflated 66%)\n",
      "  adding: kaggle/working/finetune_qwen_vim_rank_32_dropout_0.05_lr_0.0001_wd_0.001/checkpoint-1480/optimizer.pt (deflated 12%)\n",
      "  adding: kaggle/working/finetune_qwen_vim_rank_32_dropout_0.05_lr_0.0001_wd_0.001/checkpoint-1480/adapter_model.safetensors (deflated 8%)\n",
      "  adding: kaggle/working/finetune_qwen_vim_rank_32_dropout_0.05_lr_0.0001_wd_0.001/checkpoint-1480/rng_state.pth (deflated 25%)\n",
      "  adding: kaggle/working/finetune_qwen_vim_rank_32_dropout_0.05_lr_0.0001_wd_0.001/checkpoint-1480/adapter_config.json (deflated 53%)\n",
      "  adding: kaggle/working/finetune_qwen_vim_rank_32_dropout_0.05_lr_0.0001_wd_0.001/checkpoint-1480/scheduler.pt (deflated 55%)\n",
      "  adding: kaggle/working/finetune_qwen_vim_rank_32_dropout_0.05_lr_0.0001_wd_0.001/checkpoint-1480/training_args.bin (deflated 51%)\n",
      "  adding: kaggle/working/finetune_qwen_vim_rank_32_dropout_0.05_lr_0.0001_wd_0.001/checkpoint-1480/trainer_state.json (deflated 70%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /kaggle/working/folder.zip /kaggle/working/\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7032511,
     "sourceId": 11253447,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7106966,
     "sourceId": 11356198,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
